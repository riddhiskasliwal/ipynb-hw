{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 3 - basic classifiers\n",
    "\n",
    "Math practice and coding application for main classifiers introduced in Chapter 3 of the Python machine learning book. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weighting\n",
    "\n",
    "Note that this assignment is more difficult than the previous ones, and thus has a higher weighting 3 and longer duration (3 weeks). Each one of the previous two assignments has a weighting 1.\n",
    "\n",
    "Specifically, the first 3 assignments contribute to your continuous assessment as follows:\n",
    "\n",
    "Assignment weights: $w_1 = 1, w_2 = 1, w_3 = 3$\n",
    "\n",
    "Assignment grades: $g_1, g_2, g_3$\n",
    "\n",
    "Weighted average: $\\frac{1}{\\sum_i w_i} \\times \\sum_i \\left(w_i \\times g_i \\right)$\n",
    "\n",
    "Future assignments will be added analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RBF kernel (20 points)\n",
    "\n",
    "Show that a Gaussian RBF kernel can be expressed as a dot product:\n",
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{y}) \n",
    "= e^\\frac{-|\\mathbf{x} - \\mathbf{y}|^2}{2} \n",
    "= \\phi(\\mathbf{x})^T \\phi(\\mathbf{y})\n",
    "$$\n",
    "by spelling out the mapping function $\\phi$.\n",
    "\n",
    "For simplicity\n",
    "* you can assume both $\\mathbf{x}$ and $\\mathbf{y}$ are 2D vectors\n",
    "$\n",
    "x =\n",
    "\\begin{pmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{pmatrix}\n",
    ", \\;\n",
    "y =\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2\n",
    "\\end{pmatrix}\n",
    "$\n",
    "* we use a scalar unit variance here\n",
    "\n",
    "even though the proof can be extended for vectors $\\mathbf{x}$ $\\mathbf{y}$ and general covariance matrices.\n",
    "\n",
    "Hint: use Taylor series expansion of the exponential function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kernel SVM complexity (10 points)\n",
    "\n",
    "How would the complexity (or number of parameters) of a kernel SVM change with the amount of training data, and why?\n",
    "Note that the answer may depend on the specific kernel used.\n",
    "Consider specifically the following types of kernels $K(\\mathbf{x}, \\mathbf{y})$.\n",
    "* linear:\n",
    "$$\n",
    "K\\left(\\mathbf{x}, \\mathbf{y}\\right) = \\mathbf{x}^T \\mathbf{y}\n",
    "$$\n",
    "* polynomial with degree $q$:\n",
    "$$\n",
    "K\\left(\\mathbf{x}, \\mathbf{y}\\right) =\n",
    "(\\mathbf{x}^T\\mathbf{y} + 1)^q\n",
    "$$\n",
    "* RBF with distance function $D$:\n",
    "$$\n",
    "K\\left(\\mathbf{x}, \\mathbf{y} \\right) = e^{-\\frac{D\\left(\\mathbf{x}, \\mathbf{y} \\right)}{2s^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian density Bayes (30 points)\n",
    "\n",
    "$$\n",
    "p\\left(\\Theta | \\mathbf{X}\\right)\n",
    "= \n",
    "\\frac{p\\left(\\mathbf{X} | \\Theta\\right) p\\left(\\Theta\\right)}{p\\left(\\mathbf{X}\\right)}\n",
    "$$\n",
    "\n",
    "Assume both the likelihood and prior have Gaussian distributions:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{X} | \\Theta)\n",
    "&=\n",
    "\\frac{1}{(2\\pi)^{N/2}\\sigma^N} \\exp\\left(-\\frac{\\sum_{t=1}^N (\\mathbf{x}^{(t)} - \\Theta)^2}{2\\sigma^2}\\right)\n",
    "\\\\\n",
    "p(\\Theta)\n",
    "&=\n",
    "\\frac{1}{\\sqrt{2\\pi}\\sigma_0} \\exp\\left( -\\frac{(\\Theta - \\mu_0)^2}{2\\sigma_0^2} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Derive $\\Theta$ from the dataset $\\mathbf{X}$ via the following methods:\n",
    "\n",
    "### ML (maximum likelihood) estimation \n",
    "$$\n",
    "\\Theta_{ML} = argmax_{\\Theta} p(\\mathbf{X} | \\Theta)\n",
    "$$\n",
    "\n",
    "### MAP estimation\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Theta_{MAP} \n",
    "&= \n",
    "argmax_{\\Theta} p(\\Theta | \\mathbf{X})\n",
    "\\\\\n",
    "&=\n",
    "argmax_{\\Theta} p(\\mathbf{X} | \\Theta) p(\\Theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Bayes estimation\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Theta_{Bayes} \n",
    "&= \n",
    "E(\\Theta | \\mathbf{X})\n",
    "\\\\\n",
    "&= \n",
    "\\int \\Theta p(\\Theta | \\mathbf{X}) d\\Theta\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hand-written digit classification (40 points)\n",
    "\n",
    "In the textbook sample code we applied different scikit-learn classifers for the Iris data set.\n",
    "\n",
    "In this exercise, we will apply the same set of classifiers over a different data set: hand-written digits.\n",
    "Please write down the code for different classifiers, choose their hyper-parameters, and compare their performance via the accuracy score as in the Iris dataset.\n",
    "Which classifier(s) perform(s) the best and worst, and why?\n",
    "\n",
    "The classifiers include:\n",
    "* perceptron\n",
    "* logistic regression\n",
    "* SVM\n",
    "* decision tree\n",
    "* random forest\n",
    "* KNN\n",
    "* naive Bayes\n",
    "\n",
    "The dataset is available as part of scikit learn, as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data # training data\n",
    "y = digits.target # training label\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa0eedd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAEHCAYAAAByadD+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiLcQFL/D5rnyMsu16IMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa05ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "index = 13\n",
    "pl.gray()\n",
    "pl.matshow(digits.images[index])\n",
    "pl.title('digit ' + str(digits.target[index]))\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Date Preprocessing\n",
    "Hint: How you divide training and test data set? And apply other techinques we have learned if needed.\n",
    "You could take a look at the Iris data set case in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 1257, test: 540\n"
     ]
    }
   ],
   "source": [
    "#Your code comes here\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# splitting data into 70% training and 30% test data: \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "num_training = y_train.shape[0]\n",
    "num_test = y_test.shape[0]\n",
    "print('training: ' + str(num_training) + ', test: ' + str(num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #1 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 39 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(n_iter=40, eta0=0.5, random_state=0)\n",
    "_ = ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 35 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 8 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #4 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 80 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn import tree #DecisionTreeClassifier\n",
    "\n",
    "t = tree.DecisionTreeClassifier(criterion='gini')\n",
    "t.fit(X_train_std, y_train)\n",
    "y_pred = t.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifer #5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 11 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini',\n",
    "                                n_estimators=90, \n",
    "                                random_state=1,\n",
    "                                n_jobs=5)\n",
    "forest.fit(X_train_std, y_train)\n",
    "y_pred = forest.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #6 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 16 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred = knn.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Classifier #7 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 125 out of 540\n"
     ]
    }
   ],
   "source": [
    "#Your code, including traing and testing, to observe the accuracies.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "_ = gnb.fit(X_train_std, y_train)\n",
    "y_pred = gnb.predict(X_test_std)\n",
    "print('Misclassified samples: %d out of %d' % ((y_test != y_pred).sum(), y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
